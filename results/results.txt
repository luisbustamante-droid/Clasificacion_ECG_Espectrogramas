## Resultados — EfficientNetV2-B0

El modelo **EfficientNetV2-B0** alcanzó el mejor rendimiento global en la clasificación de arritmias bajo el estándar AAMI, mostrando una excelente capacidad de generalización y estabilidad durante el entrenamiento.

---

### 1. Matriz de confusión — Validación

**Archivo sugerido:** `conf_matrix_val_efficientnetv2b0.png`  
![Matriz de confusión (VAL)](./conf_matrix_val_efficientnetv2b0.png)

**Interpretación:**
- El modelo presenta una alta precisión en las clases **N** (94 %), **Q** (98 %) y **V** (94 %).
- La clase **S** (supraventricular) alcanza una precisión aceptable (74 %), aunque aún muestra confusión con la clase **N**.
- La clase **F** (fusión) continúa siendo la más difícil de identificar, con confusiones principalmente hacia **V**, pese al refuerzo con SMOTE.
- Se observa un patrón general de buena discriminación entre clases normales y ventriculares.

---

### 2. Matriz de confusión — Test

**Archivo sugerido:** `conf_matrix_test_efficientnetv2b0.png`  
![Matriz de confusión (TEST)](./conf_matrix_test_efficientnetv2b0.png)

**Interpretación:**
- En el conjunto de prueba, el modelo mantiene comportamientos similares al conjunto de validación.
- Las clases **N** (83 %), **Q** (90 %), **S** (80 %) y **V** (85 %) muestran una buena generalización.
- La clase **F** conserva un desempeño moderado (71 %), lo cual confirma que sigue siendo la categoría más desafiante.
- No se observa sobreajuste severo: las tendencias de validación y prueba son consistentes.

---

### 3. Evolución de entrenamiento — Pérdida y métricas (versión completa)

**Archivo sugerido:** `training_evolution_loss_f1_acc_efficientnetv2b0.png`  
![Evolución entrenamiento (Loss, F1, Acc)](./training_evolution_loss_f1_acc_efficientnetv2b0.png)

**Interpretación:**
- Se aprecia una disminución progresiva y estable de la pérdida en entrenamiento y validación.
- El **F1 macro** crece de 0.24 a 0.70 y el **accuracy de validación** supera el 93 %.
- No hay evidencia de sobreajuste relevante: la curva de validación se mantiene próxima a la de entrenamiento.
- El modelo converge de manera eficiente hacia la época 10.

---

### 4. Evolución — Resumen compacto (8 épocas, Cosine)

**Archivo sugerido:** `training_curve_cosine_efficientnetv2b0.png`  
![Evolución (Cosine Scheduler)](./training_curve_cosine_efficientnetv2b0.png)

**Interpretación:**
- Confirma la rápida convergencia del modelo utilizando **Cosine Annealing**.
- Las métricas de validación (F1 y Accuracy) se estabilizan desde las primeras 6–8 épocas.
- Se evidencia la eficiencia del scheduler para ajustar la tasa de aprendizaje sin pérdidas de estabilidad.

---

### 5. Conclusión

El modelo **EfficientNetV2-B0** logró los mejores resultados entre las arquitecturas evaluadas:

| Métrica | Validación | Test |
|----------|-------------|------|
| **Macro F1** | **0.7013** | **0.6495** |
| **Accuracy** | **0.9348** | **0.8327** |

Demuestra un equilibrio óptimo entre rendimiento y capacidad de generalización, consolidándose como la **arquitectura principal recomendada** para la clasificación automática de arritmias ECG en este estudio.

## Resultados — MobileNetV3-Large

El modelo **MobileNetV3-Large** logró un excelente compromiso entre precisión y eficiencia computacional, con métricas de validación y prueba muy próximas a las obtenidas con EfficientNetV2-B0.  
Su ligereza lo convierte en una opción ideal para **inferencia en tiempo real** dentro de la aplicación clínica desarrollada.

---

### 1. Matriz de confusión — Validación

**Archivo sugerido:** `conf_matrix_val_mobilenetv3large.png`  
![Matriz de confusión (VAL)](./conf_matrix_val_mobilenetv3large.png)

**Interpretación:**
- Elevada precisión en las clases **N** (91 %), **Q** (98 %) y **V** (96 %).
- La clase **S** (supraventricular) mantiene un rendimiento aceptable (68 %) aunque presenta confusión con la clase **N** (14 %).
- La clase **F** (fusión) logra 25 % de aciertos directos, con dispersión hacia **N** y **V**.
- Se conserva una estructura de confusión similar a EfficientNet, confirmando consistencia del pipeline.

---

### 2. Matriz de confusión — Test

**Archivo sugerido:** `conf_matrix_test_mobilenetv3large.png`  
![Matriz de confusión (TEST)](./conf_matrix_test_mobilenetv3large.png)

**Interpretación:**
- Buen comportamiento general de generalización:  
  - **N:** 83 % | **Q:** 93 % | **S:** 71 % | **V:** 84 %.
- La clase **F** continúa siendo la más difícil (43 % de acierto, con confusión entre **N** y **V**).
- No se observa degradación significativa respecto a la validación, lo que indica un modelo estable y sin sobreajuste relevante.

---

### 3. Evolución de entrenamiento — Pérdida y métricas (versión completa)

**Archivo sugerido:** `training_evolution_loss_f1_acc_mobilenetv3large.png`  
![Evolución entrenamiento (Loss, F1, Acc)](./training_evolution_loss_f1_acc_mobilenetv3large.png)

**Interpretación:**
- Reducción sostenida de la pérdida de entrenamiento con estabilidad en validación.
- Incremento progresivo de **F1 macro** (de 0.26 a ~0.69) y **accuracy de validación** (> 0.90).
- Convergencia estable hasta la época 12, momento en que se alcanza el mejor equilibrio entre pérdida y desempeño.

---

### 4. Evolución — Resumen compacto (20 épocas, Cosine)

**Archivo sugerido:** `training_curve_cosine_mobilenetv3large.png`  
![Evolución (Cosine Scheduler)](./training_curve_cosine_mobilenetv3large.png)

**Interpretación:**
- El **Cosine Annealing Scheduler** permitió una convergencia suave y estable.
- El modelo alcanza su punto óptimo hacia la época 10–12, manteniendo las métricas estables en el resto del entrenamiento.
- Se observa excelente equilibrio entre pérdida baja y alta precisión, confirmando su idoneidad para uso clínico.

---

### 5. Conclusión

El modelo **MobileNetV3-Large** demostró ser altamente eficiente y competitivo frente a arquitecturas más pesadas:

| Métrica | Validación | Test |
|----------|-------------|------|
| **Macro F1** | **0.6907** | **0.6277** |
| **Accuracy** | **0.9127** | **0.8046** |

En términos prácticos, MobileNetV3-Large ofrece un **rendimiento sólido con un coste computacional significativamente menor**,

## Resultados — ResNet-50

El modelo **ResNet-50** se utilizó como referencia clásica para evaluar el rendimiento de arquitecturas profundas más pesadas.  
Aunque su desempeño fue inferior al de EfficientNetV2-B0 y MobileNetV3-Large, mantuvo resultados sólidos y estables, confirmando la coherencia del pipeline de entrenamiento.

---

### 1. Matriz de confusión — Validación

**Archivo sugerido:** `conf_matrix_val_resnet50.png`  
![Matriz de confusión (VAL)](./conf_matrix_val_resnet50.png)

**Interpretación:**
- Precisión alta en **Q** (97 %) y **V** (91 %).
- La clase **S** (supraventricular) alcanza 71 % de aciertos, con confusiones hacia **N** (8 %).
- La clase **F** presenta confusión entre **N** y **V**, con 50 % de predicciones erróneas.
- Aunque el modelo identifica correctamente las clases principales, se observa menor sensibilidad en las categorías minoritarias (**F** y **S**).

---

### 2. Matriz de confusión — Test

**Archivo sugerido:** `conf_matrix_test_resnet50.png`  
![Matriz de confusión (TEST)](./conf_matrix_test_resnet50.png)

**Interpretación:**
- Buen nivel de generalización en las clases **N** (83 %), **S** (76 %) y **V** (84 %).
- Reducción en la precisión de la clase **Q** (71 %), indicando ligera pérdida de robustez frente a datos externos.
- Persisten errores en **F**, con confusiones entre **N** y **V**.
- Las tendencias entre validación y prueba se mantienen consistentes, lo que sugiere un modelo estable aunque limitado por su capacidad de generalización.

---

### 3. Evolución de entrenamiento — Pérdida y métricas (versión completa)

**Archivo sugerido:** `training_evolution_loss_f1_acc_resnet50.png`  
![Evolución entrenamiento (Loss, F1, Acc)](./training_evolution_loss_f1_acc_resnet50.png)

**Interpretación:**
- La pérdida de entrenamiento disminuye rápidamente y se estabiliza a partir de la época 3.
- El **F1 macro** de validación alcanza su pico (~0.61) en la época 6.
- Se observa un margen de diferencia entre las curvas de entrenamiento y validación, atribuible al menor número de épocas y a la complejidad de la red.

---

### 4. Evolución — Resumen compacto (6 épocas, Cosine LR)

**Archivo sugerido:** `training_curve_cosine_resnet50.png`  
![Evolución (Cosine Scheduler)](./training_curve_cosine_resnet50.png)

**Interpretación:**
- El modelo converge rápidamente en las primeras 3–4 épocas con **Cosine Annealing LR**.
- Muestra estabilidad posterior sin sobreajuste marcado, pero con una meseta de mejora limitada.
- La combinación de red profunda y dataset moderado produce resultados consistentes pero con menor F1 en comparación con EfficientNet y MobileNet.

---

### 5. Conclusión

El modelo **ResNet-50** logró un rendimiento adecuado, confirmando su fiabilidad como baseline:

| Métrica | Validación | Test |
|----------|-------------|------|
| **Macro F1** | **0.6138** | **0.6121** |
| **Accuracy** | **0.8361** | **0.8038** |

A pesar de su mayor tamaño y profundidad, **ResNet-50** no superó a las arquitecturas más modernas.  
Su desempeño demuestra que la capacidad de generalización no depende únicamente de la complejidad del modelo, sino también del balance de clases y las estrategias de regularización empleadas.
